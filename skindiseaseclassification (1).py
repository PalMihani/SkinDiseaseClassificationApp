# -*- coding: utf-8 -*-
"""SkinDiseaseClassification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eJj5sGoI02zBITnth7B6XSEhhWZfXx7-
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
ismailpromus_skin_diseases_image_dataset_path = kagglehub.dataset_download('ismailpromus/skin-diseases-image-dataset')

print('Data source import complete.')

import os
import cv2
import numpy as np
import random
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

classes = [
    'IMG_CLASSES/1. Eczema 1677',
    'IMG_CLASSES/10. Warts Molluscum and other Viral Infections - 2103',
    'IMG_CLASSES/2. Melanoma 15.75k',
    'IMG_CLASSES/3. Atopic Dermatitis - 1.25k',
    'IMG_CLASSES/4. Basal Cell Carcinoma (BCC) 3323',
    'IMG_CLASSES/5. Melanocytic Nevi (NV) - 7970',
    'IMG_CLASSES/6. Benign Keratosis-like Lesions (BKL) 2624',
    'IMG_CLASSES/7. Psoriasis pictures Lichen Planus and related diseases - 2k',
    'IMG_CLASSES/8. Seborrheic Keratoses and other Benign Tumors - 1.8k',
    'IMG_CLASSES/9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k'
    ]

import os

# Correct way to join paths
data_dir = os.path.join(ismailpromus_skin_diseases_image_dataset_path, 'IMG_CLASSES')

print(f"Dataset directory: {data_dir}")


from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_size = 224  # Your image size
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 20% of data for validation
)

# Training generator
train_generator = train_datagen.flow_from_directory(
    directory= data_dir,  # Update with your dataset directory
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

# Validation generator
validation_generator = train_datagen.flow_from_directory(
    directory= data_dir,  # Update with your dataset directory
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

import matplotlib.pyplot as plt
import numpy as np

# Fetch a batch of images from the generator
sample_batch, sample_labels = next(train_generator)

# Create a dictionary of sample images
sample_images = {f"Class {i}": sample_batch[i] for i in range(min(5, len(sample_batch)))}  # Get up to 5 sample images

# Display Augmented Images
for class_name, img in sample_images.items():
    plt.figure(figsize=(3, 3))
    plt.imshow(img)  # The images are already normalized by ImageDataGenerator
    plt.title(class_name)
    plt.axis('off')
    plt.show()

# 3. Display Augmented Images with CV Operations
for class_name, img in sample_images.items():
    print(f"Class: {class_name}")

    # Display original image
    plt.figure(figsize=(20, 10))

    # 1. Original Image
    plt.subplot(2, 5, 1)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(f"Original - {class_name}")
    plt.axis('off')

    # 2. Flipped Image
    flipped_img = cv2.flip(img, 1)
    plt.subplot(2, 5, 2)
    plt.imshow(cv2.cvtColor(flipped_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Flipped - {class_name}")
    plt.axis('off')

    # 3. Rotated Image
    h, w = img.shape[:2]
    rotation_matrix = cv2.getRotationMatrix2D((w // 2, h // 2), 15, 1)
    rotated_img = cv2.warpAffine(img, rotation_matrix, (w, h))
    plt.subplot(2, 5, 3)
    plt.imshow(cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Rotated - {class_name}")
    plt.axis('off')

    # 4. Brightness Adjustment
    bright_img = cv2.convertScaleAbs(img, alpha=1.2, beta=30)
    plt.subplot(2, 5, 4)
    plt.imshow(cv2.cvtColor(bright_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Brightened - {class_name}")
    plt.axis('off')

    # 5. Gaussian Blur
    blurred_img = cv2.GaussianBlur(img, (5, 5), 0)
    plt.subplot(2, 5, 5)
    plt.imshow(cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Blurred - {class_name}")
    plt.axis('off')

    # 6. Canny Edge Detection
    img_uint8 = (img * 255).astype(np.uint8)  # Convert to 0-255 uint8
    gray_img = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)  # Convert to grayscale
    edges_img = cv2.Canny(gray_img, 100, 200)
    plt.subplot(2, 5, 6)
    plt.imshow(edges_img, cmap='gray')
    plt.title(f"Edges - {class_name}")
    plt.axis('off')

    # 7. Color Conversion to HSV
    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    plt.subplot(2, 5, 7)
    plt.imshow(cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB))
    plt.title(f"HSV - {class_name}")
    plt.axis('off')

    # 8. Perspective Transformation
    pts1 = np.float32([[50,50],[200,50],[50,200],[200,200]])
    pts2 = np.float32([[10,100],[200,50],[100,250],[300,300]])
    matrix = cv2.getPerspectiveTransform(pts1, pts2)
    perspective_img = cv2.warpPerspective(img, matrix, (img_size, img_size))
    plt.subplot(2, 5, 8)
    plt.imshow(cv2.cvtColor(perspective_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Perspective - {class_name}")
    plt.axis('off')

    # 9. Dilation
    kernel = np.ones((5, 5), np.uint8)
    dilated_img = cv2.dilate(edges_img, kernel, iterations=1)
    plt.subplot(2, 5, 9)
    plt.imshow(dilated_img, cmap='gray')
    plt.title(f"Dilated Edges - {class_name}")
    plt.axis('off')

    # 10. Erosion
    eroded_img = cv2.erode(edges_img, kernel, iterations=1)
    plt.subplot(2, 5, 10)
    plt.imshow(eroded_img, cmap='gray')
    plt.title(f"Eroded Edges - {class_name}")
    plt.axis('off')

    plt.show()

# # 4. Normalize and One-Hot Encode Labels
# X = X / 255.0
# y = to_categorical(y, len(classes))

# # 5. Split Dataset into Train and Test Sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # 6. Create CNN Model
# model = Sequential()
# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Conv2D(64, (3, 3), activation='relu'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Conv2D(128, (3, 3), activation='relu'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Flatten())
# model.add(Dense(128, activation='relu'))
# model.add(Dropout(0.5))
# model.add(Dense(len(classes), activation='softmax'))

# # Compile the model
# model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# # 7. Train the Model
# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# # 8. Evaluate the Model
# loss, accuracy = model.evaluate(X_test, y_test)
# print(f"Test Accuracy: {accuracy * 100:.2f}%")

# from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import ImageDataGenerator from tensorflow.keras
# from tensorflow.keras.applications import VGG16
# from tensorflow.keras.models import Model
# from tensorflow.keras.layers import Dense, Flatten, Dropout
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.callbacks import ReduceLROnPlateau


# # Step 1: Load the VGG16 base model with pretrained weights
# base_model = VGG16(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')
# base_model.trainable = False  # Freeze the base model layers

# # Step 2: Add custom layers on top of VGG16 for our classification task
# x = base_model.output
# x = Flatten()(x)
# x = Dense(256, activation='relu')(x)
# x = Dropout(0.5)(x)  # Dropout layer for regularization
# predictions = Dense(len(classes), activation='softmax')(x)

# # Step 3: Define the final model
# model = Model(inputs=base_model.input, outputs=predictions)

# # Compile the model
# model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# # Optional: Unfreeze some layers for fine-tuning
# for layer in base_model.layers[-4:]:  # Unfreeze the last 4 layers for fine-tuning
#     layer.trainable = True

# # Step 4: Setup data augmentation to improve generalization
# datagen = ImageDataGenerator(
#     rotation_range=20,
#     width_shift_range=0.2,
#     height_shift_range=0.2,
#     zoom_range=0.2,
#     horizontal_flip=True
# )
# datagen.fit(X_train)

# # Step 5: Add learning rate reduction callback
# lr_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, factor=0.5, min_lr=1e-6)

# # Train the model
# model.fit(datagen.flow(X_train, y_train, batch_size=32),
#           epochs=10,
#           validation_data=(X_test, y_test),
#           callbacks=[lr_reduction])

# # Evaluate the model
# loss, accuracy = model.evaluate(X_test, y_test)
# print(f"Test Accuracy: {accuracy * 100:.2f}%")

from keras.applications import MobileNetV2
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D, Dropout
from keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau

# Define image size (adjust if necessary to match your input images)
img_size = 224  # MobileNetV2 default input size is 224x224

# Step 1: Load MobileNetV2 base model with pretrained weights
base_model = MobileNetV2(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')
base_model.trainable = False  # Freeze the base model layers initially

# Step 2: Add custom layers for your classification task
x = base_model.output
x = GlobalAveragePooling2D()(x)  # Global Average Pooling to reduce dimensions

# Additional dense layer for better learning
x = Dense(256, activation='relu')(x)  # Increased neurons
x = Dropout(0.5)(x)

x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)

# Get a batch from the train generator
batch_images, batch_labels = next(train_generator)

# Print shape of labels
print(f"Batch image shape: {batch_images.shape}")
print(f"Batch label shape: {batch_labels.shape}")

predictions = Dense(len(classes), activation='softmax')(x)

# Define the final model
model = Model(inputs=base_model.input, outputs=predictions)


# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Optional: Fine-tune by unfreezing some layers of MobileNetV2
for layer in base_model.layers[-50:]:  # Unfreeze the last 20 layers for fine-tuning
    layer.trainable = True

# Step 3: Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.2,
    zoom_range=0.3,
    horizontal_flip=True,
    brightness_range=[0.8, 1.2],  # Adjust brightness
    fill_mode='nearest'
)

# Step 4: Set up learning rate reduction callback
lr_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, factor=0.5, min_lr=1e-6)

# Train the model
history = model.fit(train_generator,
                    epochs=30,
                    validation_data=validation_generator)

# Evaluate the model
loss, accuracy = model.evaluate(validation_generator)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

import tensorflow as tf

# Save the model for later prediction
model_filename = "my_skin_disease_model"
colab_dir = "/content/saved_model"
if not os.path.exists(colab_dir):
    os.makedirs(colab_dir)

model_file_path = os.path.join(colab_dir, model_filename)

tf.saved_model.save(model,model_file_path)

model.save("skin_disease_model.h5")
print("Model has been saved in H5 format as 'skin_disease_model.h5'.")

# Convert the trained Keras model to TensorFlow Lite format

# Create a converter from the Keras model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# (Optional) Enable optimizations for smaller size & faster inference on mobile:
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# Convert the model.
tflite_model = converter.convert()

# Save the converted model to a .tflite file.
with open('skin_disease_model.tflite', 'wb') as f:
    f.write(tflite_model)

print("TFLite model conversion completed and saved as 'skin_disease_model.tflite'.")

import numpy as np

# Load the TFLite model.
interpreter = tf.lite.Interpreter(model_path="skin_disease_model.tflite")
interpreter.allocate_tensors()

# Get input and output details.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Prepare a dummy or real test image.
# Ensure the image is preprocessed in the same way as during training (e.g., resized, normalized).
# Here we create a dummy input with the required shape.
input_shape = input_details[0]['shape']
test_input = np.random.random_sample(input_shape).astype(np.float32)  # Replace with actual preprocessed image if available

# Set the input tensor.
interpreter.set_tensor(input_details[0]['index'], test_input)

# Run inference.
interpreter.invoke()

# Retrieve the output tensor.
output_data = interpreter.get_tensor(output_details[0]['index'])
print("Test prediction from the TFLite model:", output_data)

import cv2
import numpy as np
import tensorflow as tf
import os
import pickle

print("\nSKin Disease Model\n")
# Download the model

try:
    loaded_model = tf.saved_model.load("/content/saved_model/my_skin_disease_model")
    print("Model loaded successfully from SavedModel format.")
except Exception as e:
    print("Failed to load model:", e)

# Constants
IMAGE_SIZE = 224
BATCH_SIZE = 16

# Function to classify image using majority voting across three models
def classify_image_voting(image_path, loaded_model,classes):
    # Load and preprocess the image
    img = cv2.imread(image_path, cv2.IMREAD_COLOR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE)) / 255.0
    img = np.expand_dims(img, axis=0).astype(np.float32)

    # Repeat the image to create a batch of size 32
    img_batch = np.repeat(img, BATCH_SIZE, axis=0)

    # Get predictions from each model
    model_prediction = loaded_model.signatures['serving_default'](inputs=tf.constant(img_batch))
    predicted_class_index = np.argmax(model_prediction['output_0'][0])

    # Get the predicted class name using the index and the 'classes' list
    predicted_class_name = classes[predicted_class_index]

    return predicted_class_name

# Example usage:
image_path = '/content/v-03DermatitisLeg.jpg'  # Replace with your image path
predicted_disease = classify_image_voting(image_path, loaded_model, classes)
print(f"Model Prediction: {predicted_disease}")

from google.colab import drive
drive.mount('/content/drive')

!pip install numpy --upgrade --force-reinstall
!pip install tensorflow --upgrade --force-reinstall
!pip install keras --upgrade --force-reinstall

!pip install --upgrade --force-reinstall h5py